==========================================
  InferUnity Qwen2.5-0.5B å®Œæ•´è‡ªåŠ¨åŒ–è®¾ç½®
==========================================

[1;33m[1/6] è®¾ç½®Pythonè™šæ‹Ÿç¯å¢ƒ...[0m
æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ...
å®‰è£…Pythonä¾èµ–...
âœ… PyTorch: 2.2.2
âœ… Transformers: 4.57.3

[1;33m[2/6] è½¬æ¢æ¨¡å‹ä¸ºONNXæ ¼å¼...[0m
æ­£åœ¨è½¬æ¢æ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...
`torch_dtype` is deprecated! Use `dtype` instead!
Traceback (most recent call last):
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/transformers/utils/generic.py", line 1079, in wrapper
    outputs = func(self, *args, **kwargs_without_recordable)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Qwen2Model.forward() got multiple values for argument 'use_cache'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/scripts/convert_qwen_to_onnx.py", line 39, in convert_to_onnx
    torch.onnx.export(
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/onnx/utils.py", line 516, in export
    _export(
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/onnx/utils.py", line 1613, in _export
    graph, params_dict, torch_out = _model_to_graph(
                                    ^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/onnx/utils.py", line 1135, in _model_to_graph
    graph, params, torch_out, module = _create_jit_graph(model, args)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/onnx/utils.py", line 1011, in _create_jit_graph
    graph, torch_out = _trace_and_get_graph_from_model(model, args)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/onnx/utils.py", line 915, in _trace_and_get_graph_from_model
    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/jit/_trace.py", line 1296, in _get_trace_graph
    outs = ONNXTracedModule(
           ^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/jit/_trace.py", line 138, in forward
    graph, out = torch._C._create_graph_by_tracing(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/jit/_trace.py", line 129, in wrapper
    outs.append(self.inner(*trace_inputs))
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1501, in _slow_forward
    result = self.forward(*input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/transformers/utils/generic.py", line 1081, in wrapper
    raise original_exception
  File "/Users/lcf/Desktop/workspace/è¯­éŸ³/workspace/ifusionengine/venv/lib/python3.12/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Qwen2Model.forward() got multiple values for argument 'use_cache'
æ­£åœ¨åŠ è½½æ¨¡å‹: models/Qwen2.5-0.5B
âœ… æ¨¡å‹åŠ è½½æˆåŠŸ
å‡†å¤‡è¾“å…¥ (max_length=128)...
è¾“å…¥å½¢çŠ¶: torch.Size([1, 6])
è¾“å…¥ç¤ºä¾‹: [9707, 11, 1246, 525, 498, 30]

æ­£åœ¨å¯¼å‡ºONNXæ¨¡å‹åˆ°: models/Qwen2.5-0.5B/qwen2.5-0.5b.onnx
âŒ ONNXå¯¼å‡ºå¤±è´¥: Qwen2Model.forward() got multiple values for argument 'use_cache'
